{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import make_scorer, recall_score, accuracy_score\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import tqdm\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    'RandomForest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params': {\n",
    "            'n_estimators': Integer(10, 100),\n",
    "            'max_depth': Integer(3, 50),\n",
    "            'min_samples_split': Integer(2, 100)\n",
    "        }\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "        'params': {\n",
    "            'n_estimators': Integer(10, 100),\n",
    "            'max_depth': Integer(3, 50),\n",
    "            'learning_rate': Real(0.001, 1.0, 'log-uniform'),\n",
    "            'subsample': Real(0.1, 1.0)\n",
    "        }\n",
    "    },\n",
    "    'XGBRF': {\n",
    "        'model': XGBRFClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "        'params': {\n",
    "            'n_estimators': Integer(10, 100),\n",
    "            'max_depth': Integer(3, 20),\n",
    "            'learning_rate': Real(0.01, 1.0, 'log-uniform'),\n",
    "            'subsample': Real(0.5, 1.0)\n",
    "        }\n",
    "    },\n",
    "    'MLPClassifier': {\n",
    "        'model': MLPClassifier(),\n",
    "        'params': {\n",
    "            'hidden_layer_sizes': Integer(10, 200), \n",
    "        'activation': Categorical(['logistic', 'tanh', 'relu']),\n",
    "        'solver': Categorical(['sgd', 'adam']),\n",
    "        'alpha': Real(0.0001, 0.01, 'log-uniform'),\n",
    "            'learning_rate_init': Real(0.001, 0.1, prior='log-uniform'),\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Custom scorer for recall\n",
    "recall_scorer = make_scorer(recall_score)\n",
    "\n",
    "# Dataset\n",
    "with open('./reduced_data/X_boruta_cfs.pickle', 'rb') as handle:\n",
    "    X = pickle.load(handle)\n",
    "\n",
    "columns =[102, 103, 105]\n",
    "\n",
    "X = np.loadtxt('../data/x_train.txt', delimiter=' ')\n",
    "X = X[:, columns]\n",
    "y = np.loadtxt(\"../data/y_train.txt\", delimiter=' ')\n",
    "\n",
    "\n",
    "def search_test(X,y):\n",
    "    # Initialize k-fold cross-validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    best_results = {}\n",
    "\n",
    "    for name, model_info in models.items():\n",
    "        model = model_info['model']\n",
    "        params = model_info['params']\n",
    "\n",
    "        # Bayesian optimization with cross-validation\n",
    "        opt = BayesSearchCV(\n",
    "            estimator=model,\n",
    "            search_spaces=params,\n",
    "            scoring=recall_scorer,\n",
    "            cv=kf,\n",
    "            n_iter=30,\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        opt.fit(X, y)\n",
    "\n",
    "        best_model = opt.best_estimator_\n",
    "        y_pred = best_model.predict(X)\n",
    "\n",
    "        best_recall = recall_score(y, y_pred)\n",
    "        best_accuracy = accuracy_score(y, y_pred)\n",
    "\n",
    "        best_results[name] = {\n",
    "            'best_score': opt.best_score_,\n",
    "            'best_params': opt.best_params_,\n",
    "            'recall': best_recall,\n",
    "            'accuracy': best_accuracy\n",
    "        }\n",
    "\n",
    "        print(f\"Model: {name}\")\n",
    "        print(f\"Best Recall Score (CV): {opt.best_score_}\")\n",
    "        print(f\"Best Params: {opt.best_params_}\")\n",
    "        print(f\"Recall: {best_recall}\")\n",
    "        print(f\"Accuracy: {best_accuracy}\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "    class NpEncoder(json.JSONEncoder):\n",
    "        def default(self, obj):\n",
    "            if isinstance(obj, np.integer):\n",
    "                return int(obj)\n",
    "            if isinstance(obj, np.floating):\n",
    "                return float(obj)\n",
    "            if isinstance(obj, np.ndarray):\n",
    "                return obj.tolist()\n",
    "            return super(NpEncoder, self).default(obj)\n",
    "\n",
    "    # Create a dictionary to hold information about the data\n",
    "    data_info = {\n",
    "        'data_shape': X.shape,\n",
    "        'columns/file': columns,\n",
    "        'target_distribution': dict(zip(*np.unique(y, return_counts=True)))\n",
    "    }\n",
    "\n",
    "    # Combine data info with best results\n",
    "    combined_results = {'data_info': data_info, 'best_results': best_results}\n",
    "\n",
    "    # Create results directory if it doesn't exist\n",
    "    os.makedirs('results', exist_ok=True)\n",
    "\n",
    "    # Get current date and hour\n",
    "    current_time = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "    # Define the filename\n",
    "    filename = f\"results/results_{current_time}.json\"\n",
    "\n",
    "    #Save the results to a file\n",
    "    with open(filename, 'w') as f:\n",
    "       json.dump(combined_results, f, indent=4, cls=NpEncoder)\n",
    "\n",
    "    print(f\"Results saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_test(X,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
