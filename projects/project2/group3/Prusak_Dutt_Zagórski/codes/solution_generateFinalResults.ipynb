{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Dataset/x_test.txt\") as file:\n",
    "    X_test = [[float(digit) for digit in line.split()] for line in file]\n",
    "\n",
    "\n",
    "with open(\"./Dataset/x_train.txt\") as file:\n",
    "    X_train = [[float(digit) for digit in line.split()] for line in file]\n",
    "\n",
    "\n",
    "with open(\"./Dataset/y_train.txt\") as file:\n",
    "    y_train = [[float(digit) for digit in line.split()] for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ravel = np.ravel(y_train, order=\"C\")\n",
    "y_train_ravel = y_train_ravel.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinalModel:\n",
    "    \"\"\"Model with selector, scaler and a classifier that have been chosen\n",
    "    as a result of all the experiments\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.selector = SelectKBest(k=2, score_func=mutual_info_classif)\n",
    "\n",
    "        self.scaler = RobustScaler()\n",
    "\n",
    "        self.classifier = MLPClassifier(\n",
    "            activation=\"relu\",\n",
    "            beta_1=0.95,\n",
    "            beta_2=0.999,\n",
    "            solver=\"adam\",\n",
    "            alpha=0.3,\n",
    "            learning_rate=\"adaptive\",\n",
    "            learning_rate_init=0.008,\n",
    "            hidden_layer_sizes=(13,),\n",
    "            max_iter=1600,\n",
    "            random_state=42,\n",
    "        )\n",
    "\n",
    "    def fit(self, X_t, y_t):\n",
    "        X_new = self.selector.fit_transform(X_t, y_t)\n",
    "        X_new = self.scaler.fit_transform(X_new, y_t)\n",
    "        self.classifier.fit(X_new, y_t)\n",
    "\n",
    "    def predict(self, X_te, limitCount):\n",
    "        X_new = self.selector.transform(X_te)\n",
    "        X_new = self.scaler.fit_transform(X_new)\n",
    "        y_pred = self.classifier.predict_proba(X_new)\n",
    "        df = pd.DataFrame(y_pred[:, 1], columns=[\"result\"])\n",
    "        sortedDf = df.sort_values(by=\"result\", ascending=False).head(limitCount)\n",
    "\n",
    "        y_predicted = np.zeros(len(X_new))\n",
    "\n",
    "        y_predicted[sortedDf.index] = 1\n",
    "\n",
    "        selectedFeaturesIndexes = self.selector.get_support(indices=True)\n",
    "\n",
    "        return selectedFeaturesIndexes, y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalModel = FinalModel()\n",
    "\n",
    "finalModel.fit(X_train, y_train_ravel)\n",
    "\n",
    "featuresIndexes0Based, predictions = finalModel.predict(X_test, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsIndexes0Based = np.where(predictions == 1)[0]\n",
    "\n",
    "predictionsIndexes1Based = predictionsIndexes0Based + 1\n",
    "\n",
    "featuresIndexes1Based = featuresIndexes0Based + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\n",
    "    \"featuresIndexes1Based.txt\",\n",
    "    np.array(featuresIndexes1Based, dtype=int),\n",
    "    newline=\"\\n\",\n",
    "    fmt=\"%d\",\n",
    ")\n",
    "np.savetxt(\n",
    "    \"predictionsIndexes1Based.txt\",\n",
    "    np.array(predictionsIndexes1Based, dtype=int),\n",
    "    newline=\"\\n\",\n",
    "    fmt=\"%d\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([102, 137], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresIndexes1Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   3,    4,    5,    7,   12,   14,   21,   24,   25,   31,   34,\n",
       "         39,   43,   44,   55,   64,   83,   85,   88,   89,   99,  103,\n",
       "        116,  130,  131,  142,  145,  150,  151,  162,  166,  186,  189,\n",
       "        193,  198,  206,  207,  216,  217,  222,  223,  224,  227,  230,\n",
       "        237,  241,  245,  261,  271,  273,  280,  281,  285,  287,  288,\n",
       "        290,  300,  302,  315,  325,  326,  336,  339,  340,  343,  347,\n",
       "        356,  357,  358,  363,  364,  373,  374,  377,  391,  393,  399,\n",
       "        412,  415,  419,  424,  427,  429,  435,  440,  461,  469,  472,\n",
       "        475,  477,  482,  488,  491,  492,  497,  500,  507,  514,  524,\n",
       "        527,  531,  538,  551,  558,  560,  576,  578,  580,  590,  612,\n",
       "        616,  617,  619,  644,  649,  650,  656,  660,  662,  678,  679,\n",
       "        684,  685,  690,  692,  703,  704,  705,  707,  724,  725,  727,\n",
       "        732,  733,  740,  742,  749,  752,  764,  765,  769,  773,  776,\n",
       "        777,  783,  788,  792,  794,  795,  797,  802,  803,  808,  809,\n",
       "        810,  813,  824,  830,  841,  845,  847,  848,  849,  853,  854,\n",
       "        863,  871,  885,  887,  890,  893,  900,  903,  909,  912,  915,\n",
       "        916,  922,  924,  935,  937,  945,  952,  955,  968,  969,  980,\n",
       "        982,  992,  993,  999, 1006, 1009, 1018, 1021, 1028, 1031, 1037,\n",
       "       1039, 1042, 1054, 1066, 1074, 1086, 1090, 1099, 1101, 1106, 1116,\n",
       "       1117, 1118, 1124, 1134, 1139, 1143, 1146, 1147, 1154, 1158, 1159,\n",
       "       1162, 1171, 1182, 1187, 1191, 1194, 1214, 1215, 1216, 1217, 1234,\n",
       "       1239, 1241, 1243, 1246, 1251, 1252, 1253, 1256, 1267, 1269, 1271,\n",
       "       1282, 1284, 1290, 1292, 1293, 1295, 1296, 1298, 1300, 1301, 1302,\n",
       "       1305, 1309, 1313, 1325, 1328, 1330, 1332, 1353, 1360, 1361, 1371,\n",
       "       1372, 1378, 1380, 1381, 1395, 1400, 1403, 1407, 1414, 1417, 1427,\n",
       "       1439, 1444, 1455, 1461, 1463, 1475, 1483, 1484, 1492, 1496, 1505,\n",
       "       1512, 1514, 1515, 1516, 1525, 1529, 1530, 1544, 1546, 1553, 1566,\n",
       "       1567, 1570, 1580, 1585, 1600, 1602, 1606, 1611, 1612, 1614, 1615,\n",
       "       1637, 1642, 1644, 1652, 1654, 1656, 1660, 1666, 1669, 1678, 1680,\n",
       "       1681, 1687, 1696, 1703, 1707, 1736, 1742, 1743, 1745, 1746, 1749,\n",
       "       1758, 1765, 1769, 1775, 1780, 1793, 1798, 1805, 1806, 1813, 1822,\n",
       "       1825, 1827, 1828, 1832, 1834, 1837, 1838, 1840, 1862, 1870, 1871,\n",
       "       1879, 1880, 1884, 1890, 1892, 1896, 1898, 1901, 1906, 1910, 1914,\n",
       "       1927, 1929, 1931, 1932, 1938, 1941, 1948, 1950, 1953, 1954, 1960,\n",
       "       1969, 1983, 1985, 1989, 1990, 1998, 1999, 2008, 2011, 2013, 2024,\n",
       "       2031, 2039, 2041, 2046, 2049, 2053, 2067, 2071, 2076, 2077, 2079,\n",
       "       2089, 2112, 2116, 2119, 2122, 2123, 2124, 2125, 2131, 2134, 2138,\n",
       "       2139, 2152, 2153, 2160, 2168, 2178, 2183, 2187, 2189, 2191, 2200,\n",
       "       2202, 2211, 2216, 2217, 2227, 2229, 2234, 2235, 2237, 2244, 2246,\n",
       "       2247, 2249, 2252, 2253, 2255, 2257, 2266, 2272, 2284, 2286, 2287,\n",
       "       2288, 2289, 2292, 2295, 2298, 2300, 2304, 2306, 2307, 2320, 2321,\n",
       "       2332, 2336, 2346, 2355, 2358, 2359, 2360, 2364, 2370, 2371, 2383,\n",
       "       2385, 2395, 2399, 2407, 2420, 2422, 2433, 2435, 2438, 2441, 2447,\n",
       "       2449, 2450, 2452, 2455, 2456, 2457, 2462, 2466, 2475, 2479, 2482,\n",
       "       2483, 2486, 2493, 2498, 2502, 2503, 2514, 2518, 2520, 2532, 2539,\n",
       "       2546, 2547, 2555, 2563, 2565, 2574, 2578, 2582, 2592, 2594, 2596,\n",
       "       2599, 2603, 2612, 2626, 2631, 2632, 2640, 2643, 2648, 2649, 2652,\n",
       "       2657, 2665, 2672, 2682, 2685, 2688, 2690, 2693, 2696, 2700, 2711,\n",
       "       2715, 2717, 2719, 2731, 2733, 2749, 2755, 2762, 2776, 2781, 2785,\n",
       "       2793, 2796, 2797, 2801, 2810, 2822, 2828, 2836, 2839, 2845, 2862,\n",
       "       2865, 2873, 2876, 2878, 2889, 2893, 2895, 2901, 2902, 2906, 2912,\n",
       "       2913, 2921, 2924, 2925, 2927, 2928, 2930, 2931, 2938, 2939, 2944,\n",
       "       2947, 2953, 2959, 2960, 2966, 2969, 2974, 2975, 2977, 2980, 2982,\n",
       "       2989, 3001, 3010, 3020, 3028, 3031, 3032, 3033, 3034, 3035, 3041,\n",
       "       3043, 3047, 3049, 3051, 3052, 3064, 3066, 3074, 3076, 3088, 3089,\n",
       "       3090, 3093, 3094, 3100, 3113, 3124, 3125, 3129, 3135, 3141, 3146,\n",
       "       3147, 3148, 3154, 3156, 3171, 3172, 3175, 3181, 3183, 3190, 3201,\n",
       "       3203, 3206, 3211, 3212, 3216, 3222, 3227, 3230, 3237, 3240, 3243,\n",
       "       3245, 3250, 3253, 3257, 3258, 3264, 3274, 3275, 3283, 3295, 3300,\n",
       "       3307, 3308, 3309, 3310, 3317, 3320, 3324, 3331, 3336, 3342, 3350,\n",
       "       3352, 3357, 3365, 3372, 3376, 3377, 3381, 3386, 3402, 3403, 3404,\n",
       "       3407, 3408, 3411, 3426, 3433, 3438, 3439, 3443, 3454, 3463, 3466,\n",
       "       3477, 3478, 3487, 3495, 3498, 3512, 3516, 3519, 3527, 3531, 3538,\n",
       "       3547, 3558, 3560, 3563, 3564, 3580, 3581, 3584, 3587, 3599, 3601,\n",
       "       3603, 3608, 3609, 3615, 3626, 3634, 3637, 3638, 3642, 3646, 3654,\n",
       "       3658, 3660, 3661, 3662, 3664, 3665, 3666, 3674, 3680, 3681, 3684,\n",
       "       3690, 3693, 3695, 3696, 3701, 3706, 3709, 3712, 3719, 3720, 3723,\n",
       "       3735, 3736, 3739, 3742, 3743, 3749, 3754, 3755, 3763, 3767, 3775,\n",
       "       3782, 3786, 3791, 3793, 3796, 3800, 3803, 3805, 3814, 3815, 3816,\n",
       "       3820, 3822, 3824, 3833, 3839, 3842, 3852, 3856, 3858, 3859, 3865,\n",
       "       3881, 3882, 3886, 3890, 3891, 3892, 3895, 3906, 3923, 3926, 3928,\n",
       "       3929, 3930, 3935, 3937, 3948, 3949, 3951, 3956, 3957, 3960, 3963,\n",
       "       3968, 3969, 3974, 3976, 4006, 4009, 4013, 4015, 4016, 4018, 4026,\n",
       "       4027, 4035, 4045, 4048, 4051, 4055, 4065, 4073, 4080, 4096, 4098,\n",
       "       4100, 4101, 4111, 4113, 4116, 4117, 4120, 4124, 4129, 4132, 4133,\n",
       "       4135, 4138, 4139, 4147, 4152, 4157, 4161, 4163, 4173, 4177, 4181,\n",
       "       4185, 4188, 4207, 4218, 4219, 4221, 4222, 4228, 4232, 4234, 4246,\n",
       "       4251, 4253, 4258, 4261, 4270, 4271, 4274, 4285, 4286, 4288, 4289,\n",
       "       4303, 4308, 4318, 4320, 4323, 4324, 4326, 4330, 4331, 4332, 4333,\n",
       "       4336, 4339, 4349, 4350, 4354, 4363, 4370, 4380, 4382, 4387, 4388,\n",
       "       4390, 4391, 4392, 4393, 4398, 4410, 4412, 4432, 4439, 4448, 4451,\n",
       "       4452, 4459, 4467, 4475, 4477, 4483, 4484, 4489, 4490, 4499, 4501,\n",
       "       4502, 4504, 4510, 4522, 4527, 4531, 4539, 4541, 4542, 4546, 4557,\n",
       "       4558, 4559, 4564, 4570, 4580, 4581, 4585, 4591, 4596, 4597, 4600,\n",
       "       4602, 4620, 4621, 4627, 4628, 4634, 4639, 4658, 4663, 4671, 4674,\n",
       "       4677, 4691, 4709, 4714, 4718, 4722, 4723, 4725, 4728, 4729, 4730,\n",
       "       4731, 4733, 4736, 4737, 4741, 4770, 4773, 4779, 4783, 4786, 4792,\n",
       "       4793, 4800, 4808, 4811, 4814, 4820, 4822, 4831, 4833, 4835, 4847,\n",
       "       4852, 4856, 4857, 4872, 4874, 4876, 4879, 4903, 4913, 4918, 4923,\n",
       "       4925, 4926, 4931, 4934, 4937, 4938, 4940, 4944, 4946, 4962, 4963,\n",
       "       4969, 4975, 4977, 4981, 4982, 4983, 4985, 4987, 4995, 4997],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionsIndexes1Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
