{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.int = np.int32\n",
    "np.float = np.float64\n",
    "np.bool = np.bool_\n",
    "\n",
    "from boruta import BorutaPy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_features(file_name: str, features: list[tuple[str, float]]) -> None:\n",
    "    with open(f\"{file_name}.txt\", \"w\") as file:\n",
    "        for feature in features:\n",
    "            print(feature[0], file=file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature_numbers(file_path):\n",
    "    feature_numbers = []\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Strip leading/trailing whitespace and split on ' '\n",
    "            parts = line.strip().split()\n",
    "            # The number is the second part of the split line\n",
    "            if len(parts) == 2 and parts[0] == \"feature\":\n",
    "                try:\n",
    "                    feature_numbers.append(int(parts[1]))\n",
    "                except ValueError:\n",
    "                    continue  # Skip lines where the second part is not an integer\n",
    "    \n",
    "    return feature_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_matrix_to_txt(matrix, filename):\n",
    "    # Open the file in write mode\n",
    "    with open(filename, 'w') as file:\n",
    "        # Iterate over the rows of the matrix\n",
    "        for row in matrix:\n",
    "            # Convert each row to a comma-separated string\n",
    "            row_str = ','.join(map(str, row))\n",
    "            # Write the row to the file followed by a newline\n",
    "            file.write(row_str + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_path = \"../data/x_train.txt\"\n",
    "y_train_path = \"../data/y_train.txt\"\n",
    "\n",
    "x_data = np.loadtxt(x_train_path, delimiter=' ')\n",
    "y_data = np.loadtxt(y_train_path, delimiter=' ')\n",
    "\n",
    "print(\"X shape:\", x_data.shape)\n",
    "print(\"Y shape:\", y_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Y == 1:\", sum([1 for record in y_data if record == 1]))\n",
    "print(\"Y == 0:\", sum([1 for record in y_data if record == 0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "standard_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "x_data_standardized = standard_scaler.fit_transform(x_data, y_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "polunomial_builder = PolynomialFeatures()\n",
    "x_df_poly = polunomial_builder.fit_transform(x_data_standardized)\n",
    "\n",
    "print(\"X polynomialed shape:\", x_df_poly.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standarized RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "feature_names = [f\"feature {i}\" for i in range(x_data_standardized.shape[1])]\n",
    "forest = RandomForestClassifier(random_state=0)\n",
    "forest.fit(x_data_standardized, y_data)\n",
    "feature_importances = forest.feature_importances_\n",
    "\n",
    "forest_importances = {\n",
    "    feature_names[i]: feature_importances[i]\n",
    "    for i in range(len(feature_names))\n",
    "}\n",
    "\n",
    "sorted_features = sorted(\n",
    "    forest_importances.items(),\n",
    "    key=lambda x:x[1],\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "the_best_features = sorted_features[:20]\n",
    "\n",
    "save_features(f\"standarized_rfc_{len(the_best_features)}\", the_best_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomialed RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "feature_names = [f\"feature {i}\" for i in range(x_df_poly.shape[1])]\n",
    "forest = RandomForestClassifier(random_state=0)\n",
    "forest.fit(x_df_poly, y_data)\n",
    "feature_importances = forest.feature_importances_\n",
    "\n",
    "forest_importances = {\n",
    "    feature_names[i]: feature_importances[i]\n",
    "    for i in range(len(feature_names))\n",
    "}\n",
    "\n",
    "sorted_features = sorted(\n",
    "    forest_importances.items(),\n",
    "    key=lambda x:x[1],\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "the_best_features = sorted_features[:20]\n",
    "\n",
    "save_features(f\"polynomialed_rfc_{len(the_best_features)}\", the_best_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standarized Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def boruta_selection(X, y):\n",
    "    rf = RandomForestClassifier(n_jobs=-1, class_weight=\"balanced\")\n",
    "    boruta_model = BorutaPy(rf, n_estimators=\"auto\")\n",
    "    boruta_model.fit(X, y)\n",
    "\n",
    "    feature_names = [f\"feature {i}\" for i in range(x_data_standardized.shape[1])]\n",
    "    feature_importances = boruta_model.support_\n",
    "\n",
    "    the_best_features = [\n",
    "        (feature_names[i], 1.0)\n",
    "        for i in range(len(feature_names))\n",
    "        if feature_importances[i] == True\n",
    "    ]\n",
    "\n",
    "    return the_best_features\n",
    "\n",
    "the_best_features = boruta_selection(x_data_standardized, y_data)\n",
    "\n",
    "save_features(\n",
    "    f\"standarized_boruta_{len(the_best_features)}\",\n",
    "    the_best_features\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standarized KBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "select_k_best = SelectKBest(score_func=f_classif, k=10)\n",
    "X_new = select_k_best.fit_transform(x_data_standardized, y_data)\n",
    "selected_features_kbest = select_k_best.get_support(indices=True)\n",
    "selected_features_names_kbest = [(f\"feature {i}\", 1) for i in selected_features_kbest]\n",
    "\n",
    "save_features(\n",
    "    f\"standarized_kbest_{len(the_best_features)}\",\n",
    "    the_best_features\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standarized Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso(alpha=0.01)\n",
    "lasso.fit(x_data_standardized, y_data)\n",
    "selected_features_lasso = np.where(lasso.coef_ != 0)[0]\n",
    "selected_features_names_lasso = [f\"feature {i}\" for i in selected_features_lasso]\n",
    "\n",
    "save_features(\n",
    "    f\"standarized_lasso_{len(the_best_features)}\",\n",
    "    the_best_features\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boruta + Correlation Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_numbers = extract_feature_numbers('./reduced_data/standarized_boruta_10.txt')\n",
    "new_X_standarized = x_data_standardized[:, feature_numbers]\n",
    "save_matrix_to_txt(new_X_standarized, './boruta_10.txt')\n",
    "new_X_standarized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def CFS(df, threshold=0.5, show=True):\n",
    "    feature_corr = set()  \n",
    "    corr_matrix = df.corr()\n",
    "    \n",
    "    if show:\n",
    "        sns.heatmap(corr_matrix)\n",
    "\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            # absolute coeff value\n",
    "            if abs(corr_matrix.iloc[i, j]\n",
    "                   ) > threshold:  \n",
    "                # getting the name of column\n",
    "                colname = corr_matrix.columns[i]  \n",
    "                feature_corr.add(colname)\n",
    "    \n",
    "    if show:    \n",
    "        print(f'Correlated features to delete: {feature_corr}')\n",
    "    \n",
    "    return feature_corr\n",
    "\n",
    "\n",
    "feature_corr = CFS(pd.DataFrame(new_X_standarized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = list(set([n for n in range(len(feature_numbers))]).difference(set(feature_corr)))\n",
    "new_X_standarized = new_X_standarized[:, new_columns]\n",
    "new_X_standarized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('X_boruta_cfs.pickle', 'wb') as file_handle:\n",
    "    pickle.dump(new_X_standarized, file_handle)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
